[
    {
        "label": "PyPDF2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PyPDF2",
        "description": "PyPDF2",
        "detail": "PyPDF2",
        "documentation": {}
    },
    {
        "label": "HuggingFaceEmbeddings",
        "importPath": "langchain_community.embeddings",
        "description": "langchain_community.embeddings",
        "isExtraImport": true,
        "detail": "langchain_community.embeddings",
        "documentation": {}
    },
    {
        "label": "HuggingFaceEmbeddings",
        "importPath": "langchain_community.embeddings",
        "description": "langchain_community.embeddings",
        "isExtraImport": true,
        "detail": "langchain_community.embeddings",
        "documentation": {}
    },
    {
        "label": "for Chroma",
        "importPath": "langchain_chroma import Chroma  # Updated",
        "description": "langchain_chroma import Chroma  # Updated",
        "isExtraImport": true,
        "detail": "langchain_chroma import Chroma  # Updated",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "File",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "UploadFile",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "HuggingFaceEmbeddings",
        "importPath": "langchain.embeddings",
        "description": "langchain.embeddings",
        "isExtraImport": true,
        "detail": "langchain.embeddings",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "signal",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "signal",
        "description": "signal",
        "detail": "signal",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "HuggingFaceEmbeddings",
        "importPath": "langchain_huggingface",
        "description": "langchain_huggingface",
        "isExtraImport": true,
        "detail": "langchain_huggingface",
        "documentation": {}
    },
    {
        "label": "google.generativeai",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "google.generativeai",
        "description": "google.generativeai",
        "detail": "google.generativeai",
        "documentation": {}
    },
    {
        "label": "embed_data",
        "kind": 2,
        "importPath": "Import",
        "description": "Import",
        "peekOfCode": "def embed_data(data, embeddings):\n    return embeddings.embed_documents(data)  \n# Instantiate the HuggingFaceEmbeddings model\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n# Embed the extracted PDF text\nembedded_texts = embed_data(all_text, embeddings)\n# # Print each embedded vector\n# for i, vector in enumerate(embedded_texts):\n#     print(f\"Vector for Page {i + 1}: {vector}\\n\")\n# Initialize the Chroma vector store with the embeddings and original text",
        "detail": "Import",
        "documentation": {}
    },
    {
        "label": "ExampleP",
        "kind": 5,
        "importPath": "Import",
        "description": "Import",
        "peekOfCode": "ExampleP = 'SE-Lesson1.pdf'\nall_text = []\nwith open(ExampleP, 'rb') as pdffile:\n    reader = PyPDF2.PdfReader(pdffile)\n    # Extract text from each page and store in a list\n    for pagenum in range(len(reader.pages)):\n        page = reader.pages[pagenum]\n        text = page.extract_text()\n        all_text.append(text)  \n# Embedding function to embed the data",
        "detail": "Import",
        "documentation": {}
    },
    {
        "label": "all_text",
        "kind": 5,
        "importPath": "Import",
        "description": "Import",
        "peekOfCode": "all_text = []\nwith open(ExampleP, 'rb') as pdffile:\n    reader = PyPDF2.PdfReader(pdffile)\n    # Extract text from each page and store in a list\n    for pagenum in range(len(reader.pages)):\n        page = reader.pages[pagenum]\n        text = page.extract_text()\n        all_text.append(text)  \n# Embedding function to embed the data\ndef embed_data(data, embeddings):",
        "detail": "Import",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "Import",
        "description": "Import",
        "peekOfCode": "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n# Embed the extracted PDF text\nembedded_texts = embed_data(all_text, embeddings)\n# # Print each embedded vector\n# for i, vector in enumerate(embedded_texts):\n#     print(f\"Vector for Page {i + 1}: {vector}\\n\")\n# Initialize the Chroma vector store with the embeddings and original text\nvector_store = Chroma.from_texts(texts=all_text, embedding=embeddings, persist_directory=\"AssignmentDB\")\n# Use the correct method to interact with the Chroma vector store\ndocument_count = vector_store._collection.count()",
        "detail": "Import",
        "documentation": {}
    },
    {
        "label": "embedded_texts",
        "kind": 5,
        "importPath": "Import",
        "description": "Import",
        "peekOfCode": "embedded_texts = embed_data(all_text, embeddings)\n# # Print each embedded vector\n# for i, vector in enumerate(embedded_texts):\n#     print(f\"Vector for Page {i + 1}: {vector}\\n\")\n# Initialize the Chroma vector store with the embeddings and original text\nvector_store = Chroma.from_texts(texts=all_text, embedding=embeddings, persist_directory=\"AssignmentDB\")\n# Use the correct method to interact with the Chroma vector store\ndocument_count = vector_store._collection.count()\nprint(f\"Total number of documents stored: {document_count}\")\nprint(\"Vector store initialized and stored in 'AssignmentDB' directory.\")",
        "detail": "Import",
        "documentation": {}
    },
    {
        "label": "vector_store",
        "kind": 5,
        "importPath": "Import",
        "description": "Import",
        "peekOfCode": "vector_store = Chroma.from_texts(texts=all_text, embedding=embeddings, persist_directory=\"AssignmentDB\")\n# Use the correct method to interact with the Chroma vector store\ndocument_count = vector_store._collection.count()\nprint(f\"Total number of documents stored: {document_count}\")\nprint(\"Vector store initialized and stored in 'AssignmentDB' directory.\")",
        "detail": "Import",
        "documentation": {}
    },
    {
        "label": "document_count",
        "kind": 5,
        "importPath": "Import",
        "description": "Import",
        "peekOfCode": "document_count = vector_store._collection.count()\nprint(f\"Total number of documents stored: {document_count}\")\nprint(\"Vector store initialized and stored in 'AssignmentDB' directory.\")",
        "detail": "Import",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "ImportPDF",
        "description": "ImportPDF",
        "peekOfCode": "app = FastAPI()\n# Enable CORS for frontend communication\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n# Initialize the vector database or connect if already exists",
        "detail": "ImportPDF",
        "documentation": {}
    },
    {
        "label": "PERSIST_DIRECTORY",
        "kind": 5,
        "importPath": "ImportPDF",
        "description": "ImportPDF",
        "peekOfCode": "PERSIST_DIRECTORY = \"NEwMODELDB\"\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\nvector_store = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)\n@app.get(\"/pdf-count/\")\nasync def get_pdf_count(): \n    \"\"\"\n    Get the number of documents (PDFs or pages) stored in the vector database.\n    \"\"\"\n    try:\n        document_count = vector_store._collection.count()",
        "detail": "ImportPDF",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "ImportPDF",
        "description": "ImportPDF",
        "peekOfCode": "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\nvector_store = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)\n@app.get(\"/pdf-count/\")\nasync def get_pdf_count(): \n    \"\"\"\n    Get the number of documents (PDFs or pages) stored in the vector database.\n    \"\"\"\n    try:\n        document_count = vector_store._collection.count()\n        return {\"pdf_count\": document_count}",
        "detail": "ImportPDF",
        "documentation": {}
    },
    {
        "label": "vector_store",
        "kind": 5,
        "importPath": "ImportPDF",
        "description": "ImportPDF",
        "peekOfCode": "vector_store = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)\n@app.get(\"/pdf-count/\")\nasync def get_pdf_count(): \n    \"\"\"\n    Get the number of documents (PDFs or pages) stored in the vector database.\n    \"\"\"\n    try:\n        document_count = vector_store._collection.count()\n        return {\"pdf_count\": document_count}\n    except Exception as e:",
        "detail": "ImportPDF",
        "documentation": {}
    },
    {
        "label": "fetch_pdf_from_url",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def fetch_pdf_from_url(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Ensure the request was successful\n        return io.BytesIO(response.content)  # Return as a file-like object\n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching PDF: {e}\")\n        return None\n# Function to extract text from a PDF file\ndef extract_text_from_pdf(pdf_file):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "extract_text_from_pdf",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def extract_text_from_pdf(pdf_file):\n    try:\n        reader = PyPDF2.PdfReader(pdf_file)\n        all_text = [reader.pages[p].extract_text() for p in range(len(reader.pages))]\n        return all_text\n    except Exception as e:\n        print(f\"Error reading PDF: {e}\")\n        return []\n# Embedding function\ndef embed_data(data, embeddings):",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "embed_data",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def embed_data(data, embeddings):\n    return embeddings.embed_documents(data)\n# URLs of the PDFs\npdf_urls = [\n    \"https://firebasestorage.googleapis.com/v0/b/bytetcms.appspot.com/o/PDF%2F1720765368602_Handbook_of_Product_and_Service_Developm.pdf?alt=media&token=2d8f6a6c-c0bc-457e-a85e-abc4f8461f34\", \n]\n# Initialize embedding model\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n# Initialize variables for storing all text and embeddings\nall_texts = []",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "pdf_urls",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "pdf_urls = [\n    \"https://firebasestorage.googleapis.com/v0/b/bytetcms.appspot.com/o/PDF%2F1720765368602_Handbook_of_Product_and_Service_Developm.pdf?alt=media&token=2d8f6a6c-c0bc-457e-a85e-abc4f8461f34\", \n]\n# Initialize embedding model\nembeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n# Initialize variables for storing all text and embeddings\nall_texts = []\nfor url in pdf_urls:\n    print(f\"Processing PDF from URL: {url}\")\n    pdf_file = fetch_pdf_from_url(url)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n# Initialize variables for storing all text and embeddings\nall_texts = []\nfor url in pdf_urls:\n    print(f\"Processing PDF from URL: {url}\")\n    pdf_file = fetch_pdf_from_url(url)\n    if pdf_file:\n        extracted_text = extract_text_from_pdf(pdf_file)\n        if extracted_text:\n            all_texts.extend(extracted_text)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "all_texts",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "all_texts = []\nfor url in pdf_urls:\n    print(f\"Processing PDF from URL: {url}\")\n    pdf_file = fetch_pdf_from_url(url)\n    if pdf_file:\n        extracted_text = extract_text_from_pdf(pdf_file)\n        if extracted_text:\n            all_texts.extend(extracted_text)\n        else:\n            print(f\"No text extracted from: {url}\")",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "QueryResult",
        "kind": 6,
        "importPath": "Output",
        "description": "Output",
        "peekOfCode": "class QueryResult(BaseModel):\n    query: str\n# Define prompt generation function\ndef generate_rag_prompt(query, context):\n    escaped_context = context.replace(\"'\", \" \").replace('\"', \" \").replace(\"\\n\", \" \")\n    prompt = f\"\"\"\nBased on the extracted information, answer the following question directly and in a focused manner:\nQuestion: {query}\nAnswer:\n    \"\"\"",
        "detail": "Output",
        "documentation": {}
    },
    {
        "label": "signal_handler",
        "kind": 2,
        "importPath": "Output",
        "description": "Output",
        "peekOfCode": "def signal_handler(sig, frame):\n    print(\"\\nYou pressed Ctrl+C! Exiting program.\")\n    sys.exit(0)\nsignal.signal(signal.SIGINT, signal_handler)\n# Define data model for query result\nclass QueryResult(BaseModel):\n    query: str\n# Define prompt generation function\ndef generate_rag_prompt(query, context):\n    escaped_context = context.replace(\"'\", \" \").replace('\"', \" \").replace(\"\\n\", \" \")",
        "detail": "Output",
        "documentation": {}
    },
    {
        "label": "generate_rag_prompt",
        "kind": 2,
        "importPath": "Output",
        "description": "Output",
        "peekOfCode": "def generate_rag_prompt(query, context):\n    escaped_context = context.replace(\"'\", \" \").replace('\"', \" \").replace(\"\\n\", \" \")\n    prompt = f\"\"\"\nBased on the extracted information, answer the following question directly and in a focused manner:\nQuestion: {query}\nAnswer:\n    \"\"\"\n    return prompt\n# Define a function to embed and store initial data for queries\ndef initialize_vector_db(texts):",
        "detail": "Output",
        "documentation": {}
    },
    {
        "label": "initialize_vector_db",
        "kind": 2,
        "importPath": "Output",
        "description": "Output",
        "peekOfCode": "def initialize_vector_db(texts):\n    if not texts:\n        print(\"Error: No texts provided to initialize the vector database.\")\n        sys.exit(1)\n    try:\n        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n         vector_db = Chroma.from_texts(texts=texts, embedding=embeddings, persist_directory=\"./AssignmentDB\")\n        # vector_db = Chroma.from_texts(texts=texts, embedding=embeddings, persist_directory=\"./AnswerDB\")\n        return vector_db\n    except Exception as e:",
        "detail": "Output",
        "documentation": {}
    },
    {
        "label": "get_relative_context_fromDB",
        "kind": 2,
        "importPath": "Output",
        "description": "Output",
        "peekOfCode": "def get_relative_context_fromDB(query, vector_db):\n    context = \"\"\n    try:\n        search_results = vector_db.similarity_search(query, k=6)\n        for result in search_results:\n            context += result.page_content + \"\\n\"\n    except Exception as e:\n        print(f\"Error retrieving context from database: {e}\")\n    return context\n# Generate an answer based on the prompt",
        "detail": "Output",
        "documentation": {}
    },
    {
        "label": "generate_answer",
        "kind": 2,
        "importPath": "Output",
        "description": "Output",
        "peekOfCode": "def generate_answer(prompt):\n    try:\n        model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n        response = model.generate_content(prompt)\n        return response.text.strip() if response and response.text else \"No response generated.\"\n    except Exception as e:\n        return f\"Error generating answer: {e}\"\n# Main program loop\nif __name__ == \"__main__\":\n    # Replace sample_texts with actual content from a PDF or other sources",
        "detail": "Output",
        "documentation": {}
    },
    {
        "label": "Google_API_key",
        "kind": 5,
        "importPath": "Output",
        "description": "Output",
        "peekOfCode": "Google_API_key = os.getenv(\"GEMINI_API\")\nif Google_API_key:\n    genai.configure(api_key=Google_API_key)\nelse:\n    print(\"Error: Google API key not found. Please set GEMINI_API in the environment.\")\n    sys.exit(1)\n# Signal handler for clean exit\ndef signal_handler(sig, frame):\n    print(\"\\nYou pressed Ctrl+C! Exiting program.\")\n    sys.exit(0)",
        "detail": "Output",
        "documentation": {}
    }
]